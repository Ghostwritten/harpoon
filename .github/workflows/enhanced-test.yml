name: Enhanced Testing

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch:  # Allow manual triggering

permissions:
  contents: read
  packages: write

env:
  REGISTRY: docker.io
  NAMESPACE: ghostwritten
  GO_VERSION: '1.21'
  TEST_TAG_PREFIX: hpn-test-${{ github.run_id }}  # Use run_id for uniqueness

jobs:
  # Basic functionality tests across platforms
  basic-tests:
    name: Basic Tests (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Run unit tests
      run: go test -v ./...

    - name: Build binary
      run: go build -v ./cmd/hpn

    - name: Test basic functionality (Unix)
      if: runner.os != 'Windows'
      run: |
        chmod +x ./hpn
        ./hpn --version
        ./hpn -v
        ./hpn -V
        ./hpn version
        ./hpn --help | head -20

    - name: Test basic functionality (Windows)
      if: runner.os == 'Windows'
      run: |
        ./hpn.exe --version
        ./hpn.exe -v
        ./hpn.exe -V
        ./hpn.exe version
        ./hpn.exe --help

    - name: Test error handling
      shell: bash
      run: |
        # Test missing action (should fail)
        if ./hpn 2>&1 | grep -i "missing.*action"; then
          echo "‚úÖ Error handling works"
        else
          echo "‚ùå Error handling failed"
          exit 1
        fi

  # Cross-platform build tests
  build-tests:
    name: Cross-Platform Builds
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Test cross-compilation
      run: |
        # Test building for all platforms
        platforms=(
          "linux/amd64"
          "linux/arm64" 
          "darwin/amd64"
          "darwin/arm64"
          "windows/amd64"
        )
        
        for platform in "${platforms[@]}"; do
          IFS='/' read -r GOOS GOARCH <<< "$platform"
          
          if [ "$GOOS" = "windows" ]; then
            output_name="hpn-${GOOS}-${GOARCH}.exe"
          else
            output_name="hpn-${GOOS}-${GOARCH}"
          fi
          
          echo "Building for ${GOOS}/${GOARCH}..."
          
          if GOOS=${GOOS} GOARCH=${GOARCH} CGO_ENABLED=0 go build \
            -ldflags "-X main.version=v1.0-test -X main.commit=${{ github.sha }} -X main.date=$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            -o ${output_name} \
            ./cmd/hpn; then
            
            echo "‚úÖ Successfully built ${output_name}"
            ls -lh ${output_name}
            
            # Test version output for current platform
            if [ "$GOOS" = "$(go env GOOS)" ] && [ "$GOARCH" = "$(go env GOARCH)" ]; then
              echo "üß™ Testing version output:"
              ./${output_name} -v
            fi
          else
            echo "‚ùå Failed to build ${output_name}"
            exit 1
          fi
        done

    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: cross-platform-binaries
        path: hpn-*
        retention-days: 7

  # Container runtime compatibility tests
  runtime-tests:
    name: Runtime Tests (${{ matrix.runtime }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        runtime: [docker, podman]
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Install Podman
      if: matrix.runtime == 'podman'
      run: |
        sudo apt-get update
        sudo apt-get install -y podman
        podman --version

    - name: Build binary
      run: go build -o hpn ./cmd/hpn

    - name: Test runtime detection
      run: |
        echo "Testing runtime detection..."
        if command -v ${{ matrix.runtime }} >/dev/null 2>&1; then
          echo "‚úÖ ${{ matrix.runtime }}: $(${{ matrix.runtime }} --version)"
        else
          echo "‚ùå ${{ matrix.runtime }}: not installed"
          exit 1
        fi

    - name: Create test image list
      run: |
        echo "hello-world:latest" > runtime-test-images.txt
        echo "alpine:3.18" >> runtime-test-images.txt

    - name: Test pull operation
      run: |
        chmod +x ./hpn
        echo "Testing pull with ${{ matrix.runtime }}..."
        ./hpn -a pull -f runtime-test-images.txt

    - name: Verify images pulled
      run: |
        echo "Verifying pulled images..."
        ${{ matrix.runtime }} images | grep -E "(hello-world|alpine)" || echo "Images may not be visible"

    - name: Test save operation
      run: |
        echo "Testing save operation..."
        ./hpn -a save -f runtime-test-images.txt --save-mode 2
        ls -la images/ || echo "No images directory created"

    - name: Test load operation
      run: |
        echo "Testing load operation..."
        ./hpn -a load --load-mode 2 || echo "Load operation completed with warnings"

  # Integration tests with local registry
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    services:
      registry:
        image: registry:2
        ports:
          - 5000:5000
          
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Build binary
      run: go build -o hpn ./cmd/hpn

    - name: Create test image list
      run: |
        echo "hello-world:latest" > test-images.txt
        echo "alpine:3.18" >> test-images.txt

    - name: Test pull operation
      run: |
        chmod +x ./hpn
        ./hpn -a pull -f test-images.txt

    - name: Test save operation
      run: |
        ./hpn -a save -f test-images.txt --save-mode 2
        ls -la images/

    - name: Test load operation
      run: |
        ./hpn -a load --load-mode 2

    - name: Test push to local registry
      run: |
        # Tag images for local registry
        docker tag hello-world:latest localhost:5000/hello-world:latest
        docker push localhost:5000/hello-world:latest
        
        # Test hpn push to local registry
        echo "localhost:5000/hello-world:latest" > push-test.txt
        ./hpn -a push -f push-test.txt -r localhost:5000 -p test --push-mode 1 || echo "Push test completed (expected issues with local registry)"

  # End-to-end tests with Docker Hub
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request'  # Only run on push/schedule, not PRs
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Login to Docker Hub
      uses: docker/login-action@v3
      with:
        username: ${{ env.NAMESPACE }}
        password: ${{ secrets.DOCKER_HUB_TOKEN }}

    - name: Build binary
      run: go build -o hpn ./cmd/hpn

    - name: Create test image list
      run: |
        echo "hello-world:latest" > e2e-test-images.txt
        echo "alpine:3.18" >> e2e-test-images.txt

    - name: Pull test images
      run: |
        chmod +x ./hpn
        ./hpn -a pull -f e2e-test-images.txt

    - name: Save images
      run: |
        ./hpn -a save -f e2e-test-images.txt --save-mode 2

    - name: Load images
      run: |
        ./hpn -a load --load-mode 2

    - name: Tag images for push test
      run: |
        # Create push test list with target registry
        echo "${{ env.REGISTRY }}/${{ env.NAMESPACE }}/${{ env.TEST_TAG_PREFIX }}-hello:latest" > push-test-images.txt
        echo "${{ env.REGISTRY }}/${{ env.NAMESPACE }}/${{ env.TEST_TAG_PREFIX }}-alpine:latest" >> push-test-images.txt
        
        # Tag images
        docker tag hello-world:latest ${{ env.REGISTRY }}/${{ env.NAMESPACE }}/${{ env.TEST_TAG_PREFIX }}-hello:latest
        docker tag alpine:3.18 ${{ env.REGISTRY }}/${{ env.NAMESPACE }}/${{ env.TEST_TAG_PREFIX }}-alpine:latest

    - name: Push test images to Docker Hub
      run: |
        ./hpn -a push -f push-test-images.txt -r ${{ env.REGISTRY }} -p ${{ env.NAMESPACE }} --push-mode 1

    - name: Verify push success
      run: |
        echo "Verifying pushed images..."
        docker pull ${{ env.REGISTRY }}/${{ env.NAMESPACE }}/${{ env.TEST_TAG_PREFIX }}-hello:latest
        docker pull ${{ env.REGISTRY }}/${{ env.NAMESPACE }}/${{ env.TEST_TAG_PREFIX }}-alpine:latest
        echo "‚úÖ Push verification successful"

    - name: Cleanup test images
      if: always()
      run: |
        echo "Cleaning up test images..."
        # Note: Docker Hub doesn't support API deletion via CLI easily
        # In production, you might want to use Docker Hub API or manual cleanup
        echo "Test images pushed with prefix: ${{ env.TEST_TAG_PREFIX }}"
        echo "Manual cleanup may be required for: ${{ env.REGISTRY }}/${{ env.NAMESPACE }}/${{ env.TEST_TAG_PREFIX }}-*"

  # Parallel processing tests
  parallel-tests:
    name: Parallel Processing Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Build binary
      run: go build -o hpn ./cmd/hpn

    - name: Create large image list
      run: |
        # Create a list with multiple lightweight images for parallel testing
        cat > parallel-test-images.txt << EOF
        hello-world:latest
        alpine:3.18
        alpine:3.17
        busybox:1.36
        busybox:1.35
        EOF

    - name: Test parallel pull operations
      run: |
        chmod +x ./hpn
        echo "Testing parallel pull operations..."
        time ./hpn -a pull -f parallel-test-images.txt

    - name: Test parallel save operations
      run: |
        echo "Testing parallel save operations..."
        time ./hpn -a save -f parallel-test-images.txt --save-mode 2
        ls -la images/

    - name: Test parallel load operations
      run: |
        echo "Testing parallel load operations..."
        time ./hpn -a load --load-mode 2

  # Performance and resource monitoring
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Build binary
      run: go build -o hpn ./cmd/hpn

    - name: Install monitoring tools
      run: |
        sudo apt-get update
        sudo apt-get install -y time sysstat

    - name: Create performance test image list
      run: |
        cat > perf-test-images.txt << EOF
        hello-world:latest
        alpine:3.18
        busybox:1.36
        nginx:alpine
        EOF

    - name: Monitor resource usage during operations
      run: |
        chmod +x ./hpn
        
        echo "=== Performance Test: Pull Operation ==="
        /usr/bin/time -v ./hpn -a pull -f perf-test-images.txt 2>&1 | tee pull-performance.log
        
        echo "=== Performance Test: Save Operation ==="
        /usr/bin/time -v ./hpn -a save -f perf-test-images.txt --save-mode 2 2>&1 | tee save-performance.log
        
        echo "=== Performance Test: Load Operation ==="
        /usr/bin/time -v ./hpn -a load --load-mode 2 2>&1 | tee load-performance.log

    - name: Upload performance logs
      uses: actions/upload-artifact@v3
      with:
        name: performance-logs
        path: "*-performance.log"
        retention-days: 7

  # Test summary and reporting
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [basic-tests, build-tests, runtime-tests, integration-tests, parallel-tests, performance-tests]
    if: always()
    
    steps:
    - name: Generate test summary
      run: |
        echo "# üß™ Test Summary Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check job results
        if [ "${{ needs.basic-tests.result }}" == "success" ]; then
          echo "‚úÖ Basic Tests: PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå Basic Tests: FAILED" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.build-tests.result }}" == "success" ]; then
          echo "‚úÖ Build Tests: PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå Build Tests: FAILED" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.runtime-tests.result }}" == "success" ]; then
          echo "‚úÖ Runtime Tests: PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå Runtime Tests: FAILED" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.integration-tests.result }}" == "success" ]; then
          echo "‚úÖ Integration Tests: PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå Integration Tests: FAILED" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.parallel-tests.result }}" == "success" ]; then
          echo "‚úÖ Parallel Tests: PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå Parallel Tests: FAILED" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.performance-tests.result }}" == "success" ]; then
          echo "‚úÖ Performance Tests: PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ùå Performance Tests: FAILED" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Configuration" >> $GITHUB_STEP_SUMMARY
        echo "- **Registry**: ${{ env.REGISTRY }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Namespace**: ${{ env.NAMESPACE }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Go Version**: ${{ env.GO_VERSION }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Test Tag Prefix**: ${{ env.TEST_TAG_PREFIX }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "- Review failed tests if any" >> $GITHUB_STEP_SUMMARY
        echo "- Check performance logs for optimization opportunities" >> $GITHUB_STEP_SUMMARY
        echo "- Clean up test images from Docker Hub if needed" >> $GITHUB_STEP_SUMMARY